# PaddleOCR PP-OCRv5 Fine-tune å®Œæ•´æŒ‡å—

## ğŸ“š æ•¸æ“šçµæ§‹èªªæ˜

### ä½ çš„åŸå§‹æ•¸æ“šçµæ§‹ï¼š
```
binarized_data/
â”œâ”€â”€ 1/
â”‚   â”œâ”€â”€ å­—_0.png
â”‚   â”œâ”€â”€ å­—_1.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ 2/
â”œâ”€â”€ 3/
...
â””â”€â”€ 10000/

finetune_data/
â”œâ”€â”€ samples.csv        # åŒ…å«æ‰€æœ‰æ¨£æœ¬çš„è·¯å¾‘ã€å­—ç¬¦ã€ID
â””â”€â”€ id2char.json       # ID åˆ°å­—ç¬¦çš„æ˜ å°„
```

### PaddleOCR éœ€è¦çš„æ ¼å¼ï¼š
```
train_data/
â”œâ”€â”€ train_list.txt     # è¨“ç·´é›†æ¨™è¨»æ–‡ä»¶
â”œâ”€â”€ val_list.txt       # é©—è­‰é›†æ¨™è¨»æ–‡ä»¶
â””â”€â”€ custom_dict.txt    # å­—å…¸æ–‡ä»¶

binarized_data/        # åœ–ç‰‡æ•¸æ“šï¼ˆä¿æŒä¸è®Šï¼‰
â”œâ”€â”€ 1/
â”œâ”€â”€ 2/
...
```

---

## ğŸš€ å®Œæ•´è¨“ç·´æµç¨‹

### æ­¥é©Ÿ 1ï¼šæ•¸æ“šæ ¼å¼è½‰æ›

#### 1.1 ä¿®æ”¹è½‰æ›è…³æœ¬ä¸­çš„è·¯å¾‘

ç·¨è¼¯ `convert_to_paddleocr_format.py`ï¼Œä¿®æ”¹ `main()` å‡½æ•¸ä¸­çš„è·¯å¾‘ï¼š

```python
def main():
    # ä¿®æ”¹é€™äº›è·¯å¾‘ç‚ºä½ æœå‹™å™¨ä¸Šçš„å¯¦éš›è·¯å¾‘
    binarized_data_dir = "/your/path/to/binarized_data"
    samples_csv_path = "/your/path/to/finetune_data/samples.csv"
    id2char_json_path = "/your/path/to/finetune_data/id2char.json"
    output_dir = "./train_data"

    train_ratio = 0.9  # 90% è¨“ç·´ï¼Œ10% é©—è­‰
    use_relative_path = True
```

#### 1.2 é‹è¡Œè½‰æ›è…³æœ¬

```bash
python convert_to_paddleocr_format.py
```

#### 1.3 æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶

è½‰æ›å®Œæˆå¾Œæœƒç”Ÿæˆï¼š

- `train_data/train_list.txt` - è¨“ç·´é›†æ¨™è¨»æ–‡ä»¶
- `train_data/val_list.txt` - é©—è­‰é›†æ¨™è¨»æ–‡ä»¶
- `train_data/custom_dict.txt` - å­—å…¸æ–‡ä»¶
- `train_data/dataset_stats.json` - æ•¸æ“šçµ±è¨ˆ

**æª¢æŸ¥ train_list.txt çš„æ ¼å¼ï¼š**
```bash
head train_data/train_list.txt
```

æ‡‰è©²çœ‹åˆ°é¡ä¼¼çš„å…§å®¹ï¼š
```
binarized_data/5378/ç´_26.png	ç´
binarized_data/10474/é°ˆ_12.png	é°ˆ
binarized_data/1597/æ£¼_8.png	æ£¼
```

---

### æ­¥é©Ÿ 2ï¼šä¸‹è¼‰é è¨“ç·´æ¨¡å‹

```bash
# å‰µå»ºç›®éŒ„
mkdir -p pretrained

# ä¸‹è¼‰ PP-OCRv5 Mobile è­˜åˆ¥æ¨¡å‹
cd pretrained
wget https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_mobile_rec_pretrained.pdparams
cd ..

# æˆ–è€…ï¼Œå¦‚æœéœ€è¦é«˜ç²¾åº¦ï¼Œä¸‹è¼‰ Server ç‰ˆæœ¬
# wget https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_server_rec_pretrained.pdparams
```

---

### æ­¥é©Ÿ 3ï¼šå‰µå»ºæˆ–ä¿®æ”¹è¨“ç·´é…ç½®

#### é¸é … Aï¼šä½¿ç”¨è‡ªå‹•åŒ–è…³æœ¬ï¼ˆæ¨è–¦ï¼‰

ä¿®æ”¹ `prepare_and_train.sh` ä¸­çš„é…ç½®å€åŸŸï¼Œç„¶å¾Œé‹è¡Œï¼š

```bash
chmod +x prepare_and_train.sh
./prepare_and_train.sh
```

#### é¸é … Bï¼šæ‰‹å‹•å‰µå»ºé…ç½®æ–‡ä»¶

è¤‡è£½ä¸€ä»½é…ç½®æ–‡ä»¶ä¸¦ä¿®æ”¹ï¼š

```bash
cp configs/rec/PP-OCRv5/PP-OCRv5_mobile_rec.yml config_finetune.yml
```

ä¿®æ”¹ä»¥ä¸‹é—œéµåƒæ•¸ï¼š

```yaml
Global:
  pretrained_model: ./pretrained/PP-OCRv5_mobile_rec_pretrained
  character_dict_path: ./train_data/custom_dict.txt
  epoch_num: 50
  save_model_dir: ./output/PP-OCRv5_finetune
  use_space_char: false  # å¦‚æœä½ çš„æ•¸æ“šä¸éœ€è¦è­˜åˆ¥ç©ºæ ¼

Optimizer:
  lr:
    learning_rate: 0.00005  # å–®å¡è¨“ç·´å»ºè­°é™ä½å­¸ç¿’ç‡

Train:
  dataset:
    data_dir: ./
    label_file_list:
      - ./train_data/train_list.txt
  loader:
    batch_size_per_card: 64

Eval:
  dataset:
    data_dir: ./
    label_file_list:
      - ./train_data/val_list.txt
  loader:
    batch_size_per_card: 64
```

---

### æ­¥é©Ÿ 4ï¼šé–‹å§‹è¨“ç·´

#### å–®å¡è¨“ç·´
```bash
python tools/train.py -c config_finetune.yml
```

#### å¤šå¡è¨“ç·´
```bash
python -m paddle.distributed.launch --gpus '0,1,2,3' \
    tools/train.py -c config_finetune.yml \
    -o Optimizer.lr.learning_rate=0.0002  # å¤šå¡æ™‚å¯é©ç•¶æé«˜å­¸ç¿’ç‡
```

#### æ–·é»çºŒè¨“
```bash
python tools/train.py -c config_finetune.yml \
    -o Global.checkpoints=./output/PP-OCRv5_finetune/latest
```

---

### æ­¥é©Ÿ 5ï¼šç›£æ§è¨“ç·´

æŸ¥çœ‹è¨“ç·´æ—¥èªŒï¼š
```bash
tail -f output/PP-OCRv5_finetune/train.log
```

é—œéµæŒ‡æ¨™ï¼š
- `acc`: è­˜åˆ¥æº–ç¢ºç‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
- `norm_edit_dis`: æ¨™æº–åŒ–ç·¨è¼¯è·é›¢ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- `loss`: æå¤±å€¼ï¼ˆæ‡‰è©²é€æ¼¸ä¸‹é™ï¼‰

---

### æ­¥é©Ÿ 6ï¼šè©•ä¼°æ¨¡å‹

```bash
python tools/eval.py -c config_finetune.yml \
    -o Global.checkpoints=./output/PP-OCRv5_finetune/best_accuracy
```

---

### æ­¥é©Ÿ 7ï¼šå°å‡ºæ¨ç†æ¨¡å‹

```bash
python tools/export_model.py \
    -c config_finetune.yml \
    -o Global.pretrained_model=./output/PP-OCRv5_finetune/best_accuracy \
       Global.save_inference_dir=./inference/rec_model
```

---

### æ­¥é©Ÿ 8ï¼šæ¸¬è©¦æ¨¡å‹

```bash
python tools/infer_rec.py \
    -c config_finetune.yml \
    -o Global.pretrained_model=./output/PP-OCRv5_finetune/best_accuracy \
       Global.infer_img=./test_images/
```

---

## âš™ï¸ è¶…åƒæ•¸èª¿æ•´å»ºè­°

æ ¹æ“šä½ çš„æ•¸æ“šé‡å’Œç¡¬ä»¶é…ç½®ï¼š

### å¦‚æœé¡¯å­˜ä¸è¶³ï¼š
```yaml
Train:
  loader:
    batch_size_per_card: 32  # æ¸›å° batch size

Architecture:
  Backbone:
    scale: 0.5  # ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚æœ 0.95 å¤ªå¤§ï¼‰
```

### å¦‚æœæ•¸æ“šé‡è¼ƒå°‘ï¼ˆ< 10000ï¼‰ï¼š
```yaml
Optimizer:
  lr:
    learning_rate: 0.00002  # é€²ä¸€æ­¥é™ä½å­¸ç¿’ç‡
    warmup_epoch: 5  # å¢åŠ  warmup

Global:
  epoch_num: 100  # å¢åŠ è¨“ç·´è¼ªæ•¸
```

### å¦‚æœæ•¸æ“šé‡å¾ˆå¤§ï¼ˆ> 100000ï¼‰ï¼š
```yaml
Optimizer:
  lr:
    learning_rate: 0.0001  # å¯ä»¥ä½¿ç”¨è¼ƒé«˜å­¸ç¿’ç‡

Train:
  loader:
    batch_size_per_card: 128  # å¢å¤§ batch size
```

---

## ğŸ” å¸¸è¦‹å•é¡Œ

### Q1: è¨“ç·´æ™‚æç¤ºæ‰¾ä¸åˆ°åœ–ç‰‡ï¼Ÿ
**A:** æª¢æŸ¥ä»¥ä¸‹å¹¾é»ï¼š
1. `train_list.txt` ä¸­çš„è·¯å¾‘æ˜¯å¦æ­£ç¢º
2. é…ç½®æ–‡ä»¶ä¸­çš„ `data_dir` æ˜¯å¦è¨­ç½®æ­£ç¢º
3. å¦‚æœä½¿ç”¨ç›¸å°è·¯å¾‘ï¼Œç¢ºä¿è·¯å¾‘ç›¸å°æ–¼ `data_dir`

### Q2: è¨“ç·´ loss ä¸ä¸‹é™æˆ– acc ç‚º 0ï¼Ÿ
**A:** å¯èƒ½åŸå› ï¼š
1. å­¸ç¿’ç‡éé«˜æˆ–éä½ï¼Œå˜—è©¦èª¿æ•´ç‚º `5e-5` æˆ– `1e-5`
2. å­—å…¸æ–‡ä»¶ä¸åŒ¹é…ï¼Œç¢ºä¿ `custom_dict.txt` åŒ…å«æ‰€æœ‰è¨“ç·´æ•¸æ“šä¸­çš„å­—ç¬¦
3. æ•¸æ“šæ¨™è¨»æœ‰èª¤ï¼Œæª¢æŸ¥ `train_list.txt` æ ¼å¼æ˜¯å¦æ­£ç¢º

### Q3: è¨“ç·´å¾ˆæ…¢ï¼Ÿ
**A:** å„ªåŒ–å»ºè­°ï¼š
1. å¢å¤§ `batch_size_per_card`
2. å¢å¤§ `num_workers`ï¼ˆæ•¸æ“šè¼‰å…¥ç·šç¨‹æ•¸ï¼‰
3. ä½¿ç”¨å¤šå¡è¨“ç·´
4. ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ï¼ˆAMPï¼‰

### Q4: å¦‚ä½•æ¢å¾©è¨“ç·´ï¼Ÿ
**A:** ä½¿ç”¨ checkpointsï¼š
```bash
python tools/train.py -c config_finetune.yml \
    -o Global.checkpoints=./output/PP-OCRv5_finetune/iter_epoch_10
```

---

## ğŸ“Š æ•¸æ“šå¢å¼·å»ºè­°

å¦‚æœæ•¸æ“šé‡è¼ƒå°‘ï¼Œå¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­å•Ÿç”¨æ›´å¤šå¢å¼·ï¼š

```yaml
Train:
  dataset:
    transforms:
      - DecodeImage:
          img_mode: BGR
          channel_first: false
      - RecAug:  # è‡ªå‹•å¢å¼·
          prob: 0.5  # å¢å¼·æ¦‚ç‡
      - MultiLabelEncode:
          gtc_encode: NRTRLabelEncode
      - RecResizeImg:
          image_shape: [3, 48, 320]
      - KeepKeys:
          keep_keys: [image, label_ctc, label_gtc, length, valid_ratio]
```

---

## ğŸ¯ é æœŸæ•ˆæœ

æ ¹æ“šæ•¸æ“šè³ªé‡å’Œæ•¸é‡ï¼š

- **æ•¸æ“šé‡ > 50000ï¼Œè³ªé‡å¥½**ï¼šæº–ç¢ºç‡å¯é” 95%+
- **æ•¸æ“šé‡ 10000-50000**ï¼šæº–ç¢ºç‡ 85-95%
- **æ•¸æ“šé‡ < 10000**ï¼šæº–ç¢ºç‡ 70-85%

å¦‚æœæ•ˆæœä¸ç†æƒ³ï¼š
1. å¢åŠ æ•¸æ“šé‡
2. æª¢æŸ¥æ•¸æ“šè³ªé‡ï¼ˆæ¨™è¨»æº–ç¢ºæ€§ã€åœ–ç‰‡æ¸…æ™°åº¦ï¼‰
3. èª¿æ•´è¶…åƒæ•¸
4. å¢åŠ è¨“ç·´è¼ªæ•¸

---

## ğŸ“ å¿«é€Ÿæª¢æŸ¥æ¸…å–®

è¨“ç·´å‰ç¢ºèªï¼š

- [ ] å·²å®‰è£ PaddlePaddle å’Œ PaddleOCR
- [ ] å·²ä¸‹è¼‰é è¨“ç·´æ¨¡å‹
- [ ] å·²ç”Ÿæˆ train_list.txt å’Œ val_list.txt
- [ ] å·²ç”Ÿæˆ custom_dict.txt
- [ ] é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾‘éƒ½æ­£ç¢º
- [ ] æª¢æŸ¥äº†å¹¾å€‹æ¨£æœ¬çš„æ¨™è¨»æ˜¯å¦æ­£ç¢º
- [ ] ç¢ºå®šäº†åˆé©çš„ batch_size å’Œ learning_rate

---

## ğŸ’¡ å¿«é€Ÿé–‹å§‹å‘½ä»¤ï¼ˆè¤‡è£½ç²˜è²¼ï¼‰

```bash
# 1. è½‰æ›æ•¸æ“š
python convert_to_paddleocr_format.py

# 2. ä¸‹è¼‰é è¨“ç·´æ¨¡å‹
mkdir -p pretrained && cd pretrained
wget https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_mobile_rec_pretrained.pdparams
cd ..

# 3. é–‹å§‹è¨“ç·´ï¼ˆå–®å¡ï¼‰
python tools/train.py \
    -c configs/rec/PP-OCRv5/PP-OCRv5_mobile_rec.yml \
    -o Global.pretrained_model=./pretrained/PP-OCRv5_mobile_rec_pretrained \
       Global.character_dict_path=./train_data/custom_dict.txt \
       Global.save_model_dir=./output/finetune \
       Train.dataset.data_dir=./ \
       Train.dataset.label_file_list=['./train_data/train_list.txt'] \
       Eval.dataset.data_dir=./ \
       Eval.dataset.label_file_list=['./train_data/val_list.txt'] \
       Optimizer.lr.learning_rate=0.00005 \
       Train.loader.batch_size_per_card=64
```

ç¥è¨“ç·´é †åˆ©ï¼ğŸš€
